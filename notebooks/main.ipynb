{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51362240-efcd-45b4-a674-7f39641be99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RobotComp.ru\\PycharmProjects\\fullPolynomialKolmagorovGabor\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Variance</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42041.558120</td>\n",
       "      <td>237.803301</td>\n",
       "      <td>88081.578756</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>169559.177204</td>\n",
       "      <td>241.689002</td>\n",
       "      <td>162077.454328</td>\n",
       "      <td>0.534437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>176764.026388</td>\n",
       "      <td>232.418884</td>\n",
       "      <td>159735.111198</td>\n",
       "      <td>0.541165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45613.139500</td>\n",
       "      <td>133.762527</td>\n",
       "      <td>36544.863175</td>\n",
       "      <td>0.895026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>742245.503254</td>\n",
       "      <td>507.040731</td>\n",
       "      <td>628010.293242</td>\n",
       "      <td>-0.803942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22341.720634</td>\n",
       "      <td>130.503805</td>\n",
       "      <td>20189.808674</td>\n",
       "      <td>0.942005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>158653.855392</td>\n",
       "      <td>259.770714</td>\n",
       "      <td>123204.143704</td>\n",
       "      <td>0.646100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iteration       Variance         MAE            MSE       R^2\n",
       "0          1   42041.558120  237.803301   88081.578756  0.746988\n",
       "1          2  169559.177204  241.689002  162077.454328  0.534437\n",
       "2          3  176764.026388  232.418884  159735.111198  0.541165\n",
       "3          4   45613.139500  133.762527   36544.863175  0.895026\n",
       "4          5  742245.503254  507.040731  628010.293242 -0.803942\n",
       "5          6   22341.720634  130.503805   20189.808674  0.942005\n",
       "6          7  158653.855392  259.770714  123204.143704  0.646100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn. metrics import mean_absolute_error \n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class KolmogorovGaborPolynomial:\n",
    "    \"\"\"\n",
    "    Class for constructing the Kolmogorov-Gabor polynomial.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    models_dict : dict\n",
    "        Dictionary for storing trained models.\n",
    "\n",
    "    partial_polynomial_df : DataFrame\n",
    "        DataFrame for storing intermediate results during training.\n",
    "\n",
    "    stop : int\n",
    "        Number of iterations for training the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the KolmogorovGaborPolynomial class.\n",
    "        \"\"\"\n",
    "        self.models_dict = {}  # Dictionary for storing models\n",
    "\n",
    "    def fit(self, X, Y, stop=None):\n",
    "        \"\"\"\n",
    "        Train the model based on input data.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "            Input data (features).\n",
    "        Y : DataFrame or Series\n",
    "            Target values.\n",
    "        stop : int, optional\n",
    "            Number of iterations for training the model (default is None, which means using all features).\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        model : LinearRegression\n",
    "            The trained model at the last iteration.\n",
    "        \"\"\"\n",
    "        if stop is None:\n",
    "            stop = len(X.columns)\n",
    "        self.stop = stop\n",
    "\n",
    "        # Create a copy of X for modification\n",
    "        local_X = X.copy()\n",
    "\n",
    "        # Initial model (first iteration)\n",
    "        model = LinearRegression()\n",
    "        model.fit(local_X, Y)\n",
    "        predictions = model.predict(local_X)\n",
    "\n",
    "        # Create a DataFrame for storing intermediate results\n",
    "        self.partial_polynomial_df = pd.DataFrame(index=Y.index)\n",
    "        self.partial_polynomial_df['Y'] = Y.values.flatten()\n",
    "        self.partial_polynomial_df['Y_pred'] = predictions.flatten()\n",
    "\n",
    "        # Add the first column from local_X, squared, to partial_polynomial_df and remove it from local_X\n",
    "        self.partial_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "        local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        self.models_dict['1'] = model\n",
    "\n",
    "        for i in range(2, stop + 1):\n",
    "            # Add new polynomial feature of Y_pred\n",
    "            self.partial_polynomial_df[f'Y_pred^{i}'] = (predictions ** i).flatten()\n",
    "\n",
    "            # Limit prediction values to avoid overflow\n",
    "            self.partial_polynomial_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            self.partial_polynomial_df.fillna(0, inplace=True)\n",
    "\n",
    "            # Add the next column from local_X, squared, to partial_polynomial_df, if available\n",
    "            if not local_X.empty:\n",
    "                self.partial_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "                local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "            # Train a new model with additional features\n",
    "            model = LinearRegression()\n",
    "            X_new = self.partial_polynomial_df.drop(columns='Y')\n",
    "            model.fit(X_new, Y)\n",
    "            predictions = model.predict(X_new)\n",
    "\n",
    "            self.models_dict[str(i)] = model\n",
    "\n",
    "        return self.models_dict[str(stop)]\n",
    "\n",
    "    def predict(self, X, stop=None):\n",
    "        \"\"\"\n",
    "        Make predictions based on the trained model.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "            Input data (features).\n",
    "        stop : int, optional\n",
    "            Number of iterations for prediction (default is None, which means using self.stop value).\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        predictions : ndarray\n",
    "            Predicted values.\n",
    "        \"\"\"\n",
    "        if stop is None:\n",
    "            stop = self.stop\n",
    "\n",
    "        # Create a copy of X for modification\n",
    "        local_X = X.copy()\n",
    "\n",
    "        # Initial predictions\n",
    "        model = self.models_dict['1']\n",
    "        predictions = model.predict(local_X)\n",
    "\n",
    "        if stop == 1:\n",
    "            return predictions\n",
    "\n",
    "        # Create a DataFrame for storing intermediate prediction results\n",
    "        predict_polynomial_df = pd.DataFrame(index=X.index)\n",
    "        predict_polynomial_df['Y_pred'] = predictions.flatten()\n",
    "\n",
    "        # Add the first column from local_X, squared, to predict_polynomial_df and remove it from local_X\n",
    "        predict_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "        local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        for i in range(2, stop + 1):\n",
    "            # Add new polynomial feature of Y_pred\n",
    "            predict_polynomial_df[f'Y_pred^{i}'] = (predictions ** i).flatten()\n",
    "\n",
    "            # Limit prediction values to avoid overflow\n",
    "            predict_polynomial_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            predict_polynomial_df.fillna(0, inplace=True)\n",
    "\n",
    "            # Add the next column from local_X, squared, to predict_polynomial_df, if available\n",
    "            if not local_X.empty:\n",
    "                predict_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "                local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "            model = self.models_dict[str(i)]\n",
    "            predictions = model.predict(predict_polynomial_df)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Пример использования класса\n",
    "# Создаем экземпляр класса\n",
    "kpg = KolmogorovGaborPolynomial()\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_excel(r'C:\\Users\\RobotComp.ru\\PycharmProjects\\fullPolynomialKolmagorovGabor\\datasets\\polynom_miroshnichenko.xlsx', sheet_name='data')\n",
    "Y = df[['Металл и добыча (Y3)']]\n",
    "X = df.drop(columns=['Металл и добыча (Y3)', 'Дата'])\n",
    "\n",
    "# Разделение данных на обучающие и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Переменные для хранения дисперсий, MAE, MSE и R^2\n",
    "variances = []\n",
    "maes = []\n",
    "mses = []\n",
    "r2_scores = []\n",
    "\n",
    "# Цикл по количеству колонок в X\n",
    "for i in range(1, len(X_train.columns) + 1):\n",
    "    # Обучение модели с текущим значением stop\n",
    "    kpg.fit(X_train, Y_train, stop=i)\n",
    "    # print(kpg.models_dict)\n",
    "    # Получение предсказаний\n",
    "    predictions = kpg.predict(X=X_test, stop=i)\n",
    "    # Вычисление ошибок\n",
    "    errors = Y_test.values.flatten() - predictions.flatten()\n",
    "    # Вычисление дисперсии ошибок\n",
    "    sample_variance = errors.var(ddof=1)\n",
    "    # Вычисление MAE\n",
    "    mae = mean_absolute_error(Y_test.values.flatten(), predictions.flatten())\n",
    "    # Вычисление MSE\n",
    "    mse = mean_squared_error(Y_test.values.flatten(), predictions.flatten())\n",
    "    # Вычисление R^2\n",
    "    r2 = r2_score(Y_test.values.flatten(), predictions.flatten())\n",
    "    # Добавление дисперсии, MAE, MSE и R^2 в списки\n",
    "    variances.append(sample_variance)\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Создание DataFrame из дисперсий, MAE, MSE и R^2\n",
    "results_df = pd.DataFrame({\n",
    "    'Iteration': range(1, len(X.columns) + 1),\n",
    "    'Variance': variances,\n",
    "    'MAE': maes,\n",
    "    'MSE': mses,\n",
    "    'R^2': r2_scores\n",
    "})\n",
    "\n",
    "# Вывод таблицы DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d644bceb-9093-492e-90f1-95562ef912e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Variance</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3996.548622</td>\n",
       "      <td>52.949550</td>\n",
       "      <td>3761.457527</td>\n",
       "      <td>0.977236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3353.772168</td>\n",
       "      <td>45.969039</td>\n",
       "      <td>3156.491452</td>\n",
       "      <td>0.980897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2271.327350</td>\n",
       "      <td>35.632307</td>\n",
       "      <td>2137.719859</td>\n",
       "      <td>0.987063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011.071479</td>\n",
       "      <td>36.701471</td>\n",
       "      <td>1892.773157</td>\n",
       "      <td>0.988545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1486.503524</td>\n",
       "      <td>30.664164</td>\n",
       "      <td>1399.062140</td>\n",
       "      <td>0.991533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3693.897409</td>\n",
       "      <td>46.370132</td>\n",
       "      <td>3476.609326</td>\n",
       "      <td>0.978960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2040.199542</td>\n",
       "      <td>32.150861</td>\n",
       "      <td>1920.187804</td>\n",
       "      <td>0.988379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iteration     Variance        MAE          MSE       R^2\n",
       "0          1  3996.548622  52.949550  3761.457527  0.977236\n",
       "1          2  3353.772168  45.969039  3156.491452  0.980897\n",
       "2          3  2271.327350  35.632307  2137.719859  0.987063\n",
       "3          4  2011.071479  36.701471  1892.773157  0.988545\n",
       "4          5  1486.503524  30.664164  1399.062140  0.991533\n",
       "5          6  3693.897409  46.370132  3476.609326  0.978960\n",
       "6          7  2040.199542  32.150861  1920.187804  0.988379"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn. metrics import mean_absolute_error \n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class KolmogorovGaborPolynomial:\n",
    "    \"\"\"\n",
    "    Class for constructing the Kolmogorov-Gabor polynomial.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    models_dict : dict\n",
    "        Dictionary for storing trained models.\n",
    "\n",
    "    partial_polynomial_df : DataFrame\n",
    "        DataFrame for storing intermediate results during training.\n",
    "\n",
    "    stop : int\n",
    "        Number of iterations for training the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the KolmogorovGaborPolynomial class.\n",
    "        \"\"\"\n",
    "        self.models_dict = {}  # Dictionary for storing models\n",
    "\n",
    "    def fit(self, X, Y, stop=None):\n",
    "        \"\"\"\n",
    "        Train the model based on input data.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "            Input data (features).\n",
    "        Y : DataFrame or Series\n",
    "            Target values.\n",
    "        stop : int, optional\n",
    "            Number of iterations for training the model (default is None, which means using all features).\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        model : LinearRegression\n",
    "            The trained model at the last iteration.\n",
    "        \"\"\"\n",
    "        if stop is None:\n",
    "            stop = len(X.columns)\n",
    "        self.stop = stop\n",
    "\n",
    "        # Create a copy of X for modification\n",
    "        local_X = X.copy()\n",
    "\n",
    "        # Initial model (first iteration)\n",
    "        model = LinearRegression()\n",
    "        model.fit(local_X, Y)\n",
    "        predictions = model.predict(local_X)\n",
    "\n",
    "        # Create a DataFrame for storing intermediate results\n",
    "        self.partial_polynomial_df = pd.DataFrame(index=Y.index)\n",
    "        self.partial_polynomial_df['Y'] = Y.values.flatten()\n",
    "        self.partial_polynomial_df['Y_pred'] = predictions.flatten()\n",
    "\n",
    "        # Add the first column from local_X, squared, to partial_polynomial_df and remove it from local_X\n",
    "        self.partial_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "        local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        self.models_dict['1'] = model\n",
    "\n",
    "        for i in range(2, stop + 1):\n",
    "            # Add new polynomial feature of Y_pred\n",
    "            self.partial_polynomial_df[f'Y_pred^{i}'] = (predictions ** i).flatten()\n",
    "\n",
    "            # Limit prediction values to avoid overflow\n",
    "            self.partial_polynomial_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            self.partial_polynomial_df.fillna(0, inplace=True)\n",
    "\n",
    "            # Add the next column from local_X, squared, to partial_polynomial_df, if available\n",
    "            if not local_X.empty:\n",
    "                self.partial_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "                local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "            # Train a new model with additional features\n",
    "            model = LinearRegression()\n",
    "            X_new = self.partial_polynomial_df.drop(columns='Y')\n",
    "            model.fit(X_new, Y)\n",
    "            predictions = model.predict(X_new)\n",
    "\n",
    "            self.models_dict[str(i)] = model\n",
    "\n",
    "        return self.models_dict[str(stop)]\n",
    "\n",
    "    def predict(self, X, stop=None):\n",
    "        \"\"\"\n",
    "        Make predictions based on the trained model.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "            Input data (features).\n",
    "        stop : int, optional\n",
    "            Number of iterations for prediction (default is None, which means using self.stop value).\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        predictions : ndarray\n",
    "            Predicted values.\n",
    "        \"\"\"\n",
    "        if stop is None:\n",
    "            stop = self.stop\n",
    "\n",
    "        # Create a copy of X for modification\n",
    "        local_X = X.copy()\n",
    "\n",
    "        # Initial predictions\n",
    "        model = self.models_dict['1']\n",
    "        predictions = model.predict(local_X)\n",
    "\n",
    "        if stop == 1:\n",
    "            return predictions\n",
    "\n",
    "        # Create a DataFrame for storing intermediate prediction results\n",
    "        predict_polynomial_df = pd.DataFrame(index=X.index)\n",
    "        predict_polynomial_df['Y_pred'] = predictions.flatten()\n",
    "\n",
    "        # Add the first column from local_X, squared, to predict_polynomial_df and remove it from local_X\n",
    "        predict_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "        local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        for i in range(2, stop + 1):\n",
    "            # Add new polynomial feature of Y_pred\n",
    "            predict_polynomial_df[f'Y_pred^{i}'] = (predictions ** i).flatten()\n",
    "\n",
    "            # Limit prediction values to avoid overflow\n",
    "            predict_polynomial_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            predict_polynomial_df.fillna(0, inplace=True)\n",
    "\n",
    "            # Add the next column from local_X, squared, to predict_polynomial_df, if available\n",
    "            if not local_X.empty:\n",
    "                predict_polynomial_df[local_X.columns[0] + '^2'] = local_X.iloc[:, 0] ** 2\n",
    "                local_X.drop(local_X.columns[0], axis=1, inplace=True)\n",
    "\n",
    "            model = self.models_dict[str(i)]\n",
    "            predictions = model.predict(predict_polynomial_df)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# Пример использования класса\n",
    "# Создаем экземпляр класса\n",
    "kpg = KolmogorovGaborPolynomial()\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_excel(r'C:\\Users\\RobotComp.ru\\PycharmProjects\\kolmagorovGabor\\data\\polynom_miroshnichenko.xlsx', sheet_name='data')\n",
    "Y = df[['Металл и добыча (Y3)']]\n",
    "X = df.drop(columns=['Металл и добыча (Y3)', 'Дата'])\n",
    "\n",
    "# Разделение данных на обучающие и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Переменные для хранения дисперсий, MAE, MSE и R^2\n",
    "variances = []\n",
    "maes = []\n",
    "mses = []\n",
    "r2_scores = []\n",
    "\n",
    "# Цикл по количеству колонок в X\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    # Обучение модели с текущим значением stop\n",
    "    kpg.fit(X, Y, stop=i)\n",
    "    # print(kpg.models_dict)\n",
    "    # Получение предсказаний\n",
    "    predictions = kpg.predict(X=X, stop=i)\n",
    "    # Вычисление ошибок\n",
    "    errors = Y.values.flatten() - predictions.flatten()\n",
    "    # Вычисление дисперсии ошибок\n",
    "    sample_variance = errors.var(ddof=1)\n",
    "    # Вычисление MAE\n",
    "    mae = mean_absolute_error(Y.values.flatten(), predictions.flatten())\n",
    "    # Вычисление MSE\n",
    "    mse = mean_squared_error(Y.values.flatten(), predictions.flatten())\n",
    "    # Вычисление R^2\n",
    "    r2 = r2_score(Y.values.flatten(), predictions.flatten())\n",
    "    # Добавление дисперсии, MAE, MSE и R^2 в списки\n",
    "    variances.append(sample_variance)\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Создание DataFrame из дисперсий, MAE, MSE и R^2\n",
    "results_df = pd.DataFrame({\n",
    "    'Iteration': range(1, len(X.columns) + 1),\n",
    "    'Variance': variances,\n",
    "    'MAE': maes,\n",
    "    'MSE': mses,\n",
    "    'R^2': r2_scores\n",
    "})\n",
    "\n",
    "# Вывод таблицы DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5796785-7509-4f0b-ba65-b3ecb7a3dd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
